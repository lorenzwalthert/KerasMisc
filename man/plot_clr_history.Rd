% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/plot.R
\name{plot_clr_history}
\alias{plot_clr_history}
\title{Simple plotting utility}
\usage{
plot_clr_history(
  callback_clr,
  granularity = "epoch",
  backend = "ggplot2",
  trans_y_axis = "identity"
)
}
\arguments{
\item{callback_clr}{An object of class \code{CyclicLR}.}

\item{granularity}{Either "epoch" or "iteration". We advise to use epoch
as we find it easier to work with. The plot will look very similar (except
for the x-axis scaling) for both options as long as you choosed \code{step_size}
in \code{\link[=new_callback_cyclical_learning_rate]{new_callback_cyclical_learning_rate()}} to be more iterations than
one epoch has.}

\item{backend}{Either "base" for base R or "ggplot2".}

\item{trans_y_axis}{Value passed to \code{\link[ggplot2:scale_continuous]{ggplot2::scale_y_continuous()}} as the
\code{trans} argument. Only supported for \code{backend = "ggplot2"}.}
}
\description{
Simple plotting utility
}
\examples{
library(keras)
dataset <- dataset_boston_housing()
c(c(train_data, train_targets), c(test_data, test_targets)) \%<-\% dataset

mean <- apply(train_data, 2, mean)
std <- apply(train_data, 2, sd)
train_data <- scale(train_data, center = mean, scale = std)
test_data <- scale(test_data, center = mean, scale = std)


model <- keras_model_sequential() \%>\%
  layer_dense(
    units = 64, activation = "relu",
    input_shape = dim(train_data)[[2]]
  ) \%>\%
  layer_dense(units = 64, activation = "relu") \%>\%
  layer_dense(units = 1)
model \%>\% compile(
  optimizer = optimizer_rmsprop(lr = 0.001),
  loss = "mse",
  metrics = c("mae")
)

callback_clr <- new_callback_cyclical_learning_rate(
  step_size = 32,
  base_lr = 0.001,
  max_lr = 0.006,
  gamma = 0.99,
  mode = "exp_range"
)
model \%>\% fit(
  train_data, train_targets,
  validation_data = list(test_data, test_targets),
  epochs = 10, verbose = 1,
  callbacks = list(callback_clr)
)
callback_clr$history
plot_clr_history(callback_clr, backend = "base")
}
